{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc1185e5-bdac-45cf-a338-0f76256b242f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T22:48:18.290595Z",
     "iopub.status.busy": "2025-07-22T22:48:18.290256Z",
     "iopub.status.idle": "2025-07-22T22:48:21.843665Z",
     "shell.execute_reply": "2025-07-22T22:48:21.843051Z",
     "shell.execute_reply.started": "2025-07-22T22:48:18.290578Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate bitsandbytes einops\n",
    "!pip install -q pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9ab27-56bc-4e63-98f3-fdabfa445229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T22:48:22.820966Z",
     "iopub.status.busy": "2025-07-22T22:48:22.820592Z",
     "iopub.status.idle": "2025-07-22T22:48:23.235268Z",
     "shell.execute_reply": "2025-07-22T22:48:23.234701Z",
     "shell.execute_reply.started": "2025-07-22T22:48:22.820946Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bbdeff-eead-4de7-8c7a-8e10aa1f2b4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T23:16:28.428325Z",
     "iopub.status.busy": "2025-07-22T23:16:28.427929Z",
     "iopub.status.idle": "2025-07-22T23:28:40.994669Z",
     "shell.execute_reply": "2025-07-22T23:28:40.994087Z",
     "shell.execute_reply.started": "2025-07-22T23:16:28.428306Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 23:16:41.463949: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753226201.489751    2980 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753226201.499609    2980 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-22 23:16:41.708990: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949645cd899b424aa4d359703315a9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=8192,\n",
    "    do_sample=False,\n",
    "    return_full_text=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d59afd-54bc-492c-aa94-8ddb94f9561e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T23:28:46.930026Z",
     "iopub.status.busy": "2025-07-22T23:28:46.929442Z",
     "iopub.status.idle": "2025-07-22T23:28:46.932895Z",
     "shell.execute_reply": "2025-07-22T23:28:46.932437Z",
     "shell.execute_reply.started": "2025-07-22T23:28:46.930009Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_cv_text(text):\n",
    "    import re\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58804de1-1726-4f8e-8841-6d6dafed1452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T23:28:49.427995Z",
     "iopub.status.busy": "2025-07-22T23:28:49.427809Z",
     "iopub.status.idle": "2025-07-22T23:28:49.620884Z",
     "shell.execute_reply": "2025-07-22T23:28:49.620388Z",
     "shell.execute_reply.started": "2025-07-22T23:28:49.427981Z"
    }
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text= \"\\n\".join(page.get_text() for page in doc).strip()\n",
    "    return preprocess_cv_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5540b312-8f9d-4002-b64f-00d5e3ef33bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T23:28:53.104439Z",
     "iopub.status.busy": "2025-07-22T23:28:53.104049Z",
     "iopub.status.idle": "2025-07-22T23:28:53.107359Z",
     "shell.execute_reply": "2025-07-22T23:28:53.106767Z",
     "shell.execute_reply.started": "2025-07-22T23:28:53.104423Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt(cv_text):\n",
    "    return f\"\"\"\n",
    "Tu es un extracteur d'informations structuré. À partir du texte du CV ci-dessous, fournis un objet JSON valide contenant les champs suivants :\n",
    "\n",
    "- name\n",
    "- profile\n",
    "- phone\n",
    "- email\n",
    "- address\n",
    "- experience (liste de: company, title, start_date, end_date, description)\n",
    "- education (liste de: university, degree, start_date, end_date, description)\n",
    "- certifications (liste de: title, organization, date, description)\n",
    "- skills (liste de chaînes)\n",
    "\n",
    "Donne uniquement un JSON valide avec tout le text du CV n’oublie aucun mot, sans commentaire ni texte en plus.\n",
    "\n",
    "CV:\n",
    "\\\"\\\"\\\"{cv_text}\\\"\\\"\\\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228574b8-46b9-4c46-9d53-2b0fda97eb86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T23:28:57.784393Z",
     "iopub.status.busy": "2025-07-22T23:28:57.784032Z",
     "iopub.status.idle": "2025-07-22T23:30:27.924549Z",
     "shell.execute_reply": "2025-07-22T23:30:27.923996Z",
     "shell.execute_reply.started": "2025-07-22T23:28:57.784375Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```json\n",
      "{\n",
      "  \"name\": \"Achraf HADJ TAIEB\",\n",
      "  \"profile\": \"Directeur IT et Chef de projet expérimenté, certifié Agile Scrum PSPO I, avec plus de 16 ans d’expérience dans la gestion de projets stratégiques et la conduite de transformations digitales.\",\n",
      "  \"phone\": \"+33 6 44 18 07 72\",\n",
      "  \"email\": \"achraf.ht@gmail.com\",\n",
      "  \"address\": {\n",
      "    \"location\": \"Paris\",\n",
      "    \"carbonne\": \"9.78 g CO₂e\"\n",
      "  },\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"company\": \"Allianz Trade\",\n",
      "      \"title\": \"Directeur et Chef de projet IT\",\n",
      "      \"start_date\": \"Nov 2021\",\n",
      "      \"end_date\": \"Dec 2024\",\n",
      "      \"description\": \"Programme Qirin - Document Services\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"AXA Assurance\",\n",
      "      \"title\": \"Squad RH de AXA France\",\n",
      "      \"start_date\": \"Janv 2021\",\n",
      "      \"end_date\": \"Novembre 2021\",\n",
      "      \"description\": \"Digitalisation des processus RH\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"Finbill\",\n",
      "      \"title\": \"Project Manager\",\n",
      "      \"start_date\": \"Avril. 2019\",\n",
      "      \"end_date\": \"Dec 2020\",\n",
      "      \"description\": \"Stratup dans l’objectif est de fournir une solution de facturation et de paiement en ligne (Web et Mobile) pour répondre aux obligations légales de la facture dématérialisée basée sur la technologie Blockchain.\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"Ville de Bruxelles\",\n",
      "      \"title\": \"Digitalisation des processus métier IT Manager\",\n",
      "      \"start_date\": \"De mars 2017 Avril. 2019\",\n",
      "      \"end_date\": null,\n",
      "      \"description\": \"Digital Transformation Program\"\n",
      "    }\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"university\": \"Faculté des sciences de Sfax\",\n",
      "      \"degree\": \"Maitrise Informatique, option réseaux et systèmes distribués\",\n",
      "      \"start_date\": \"2007\",\n",
      "      \"end_date\": null,\n",
      "      \"description\": null\n",
      "    },\n",
      "    {\n",
      "      \"university\": \"École nationale d'ingénieur de Sfax – Tunisie\",\n",
      "      \"degree\": \"Master Technologies de l’information\",\n",
      "      \"start_date\": \"2008\",\n",
      "      \"end_date\": null,\n",
      "      \"description\": null\n",
      "    }\n",
      "  ],\n",
      "  \"certifications\": [\n",
      "    {\n",
      "      \"title\": \"Certification. PSPO1\",\n",
      "      \"organization\": \"Formation méthode agile scrum\",\n",
      "      \"date\": \"2019\",\n",
      "      \"description\": null\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Managériales\",\n",
      "    \"Chefferie/Directions de projet\",\n",
      "    \"Fonctionnelles\",\n",
      "    \"Techniques\",\n",
      "    \"Méthodologie\",\n",
      "    \"Secteur métier : Banque & Assurance, E-commerce et marketing digitale, Ressources humaines\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_path = \"CV_Achraf_HT_Directeur et Chef de projet IT_2025.pdf\"\n",
    "\n",
    "cv_text = extract_text_from_pdf(pdf_path)\n",
    "prompt = build_prompt(cv_text)\n",
    "\n",
    "output = pipe(prompt)[0][\"generated_text\"]\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aed0dc7-0d01-4769-849e-6a50042bdd0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T23:30:34.361475Z",
     "iopub.status.busy": "2025-07-22T23:30:34.361136Z",
     "iopub.status.idle": "2025-07-22T23:30:34.365168Z",
     "shell.execute_reply": "2025-07-22T23:30:34.364675Z",
     "shell.execute_reply.started": "2025-07-22T23:30:34.361458Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt_position(cv_text):\n",
    "    return f\"\"\"\n",
    "You are an information extractor. Do not generate or summarize. Your job is to locate and extract named entities and sections from a CV **exactly as they appear in the text**.\n",
    "\n",
    "Your goal is to extract the following entities by identifying the **first word and last word** that mark the boundaries of each entity or section. Do not infer, rephrase, or invent content. Use only what is present in the CV.\n",
    "\n",
    "### Extract the following fields:\n",
    "\n",
    "- name: first word, last word  \n",
    "- email: first word, last word  \n",
    "- phone: first word, last word  \n",
    "- address: first word, last word (if available)  \n",
    "- profile_description: first word, last word  \n",
    "- education (for each degree): first word, last word  \n",
    "- experience (for each job):  \n",
    "    - company_name: first word, last word  \n",
    "    - position_title: first word, last word  \n",
    "    - start_date: first word, last word  \n",
    "    - end_date: first word, last word  \n",
    "    - description: first word, last word  \n",
    "- projects (for each project):  \n",
    "    - title: first word, last word  \n",
    "    - description: first word, last word  \n",
    "\n",
    "### Output Format:\n",
    "Return your result in this **valid JSON** format:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"name\": {{\"start\": \"Achraf\", \"end\": \"TAIEB\"}},\n",
    "  \"email\": {{\"start\": \"achraf.ht\", \"end\": \".com\"}},\n",
    "  \"phone\": {{\"start\": \"+33\", \"end\": \"72\"}},\n",
    "  \"profile_description\": {{\"start\": \"Directeur\", \"end\": \"conformité.\"}},\n",
    "  \"education\": [\n",
    "    {{\"start\": \"Maitrise\", \"end\": \"Sfax\"}},\n",
    "    {{\"start\": \"Master\", \"end\": \"Sfax\"}},\n",
    "    {{\"start\": \"Formation\", \"end\": \"PSPO1\"}}\n",
    "  ],\n",
    "  \"experiences\": [\n",
    "    {{\n",
    "      \"company_name\": {{\"start\": \"Allianz\", \"end\": \"Trade\"}},\n",
    "      \"position_title\": {{\"start\": \"Manager\", \"end\": \"owner\"}},\n",
    "      \"start_date\": {{\"start\": \"Nov\", \"end\": \"2021\"}},\n",
    "      \"end_date\": {{\"start\": \"Dec\", \"end\": \"2024\"}},\n",
    "      \"description\": {{\"start\": \"Allianz\", \"end\": \"production\"}}\n",
    "    }}\n",
    "  ],\n",
    "  \"projects\": [\n",
    "    {{\n",
    "      \"title\": {{\"start\": \"Projet\", \"end\": \"Audit\"}},\n",
    "      \"description\": {{\"start\": \"Audit\", \"end\": \"pilotage\"}}\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "CV:\n",
    "\\\"\\\"\\\"{cv_text}\\\"\\\"\\\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78c0a0-7abc-4e71-907b-8e9e0870802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_path = \"CV_Achraf_HT_Directeur et Chef de projet IT_2025.pdf\"\n",
    "\n",
    "\n",
    "cv_text1 = extract_text_from_pdf(pdf_path)\n",
    "prompt = build_prompt_position(cv_text)\n",
    "\n",
    "output = pipe(prompt)[0][\"generated_text\"]\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1899c3-d93a-4b32-8c9a-6210dcf9c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0231e2d-d450-4609-94bf-dacee955e958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T23:30:42.568460Z",
     "iopub.status.busy": "2025-07-22T23:30:42.567943Z",
     "iopub.status.idle": "2025-07-22T23:30:42.626034Z",
     "shell.execute_reply": "2025-07-22T23:30:42.625493Z",
     "shell.execute_reply.started": "2025-07-22T23:30:42.568443Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# 1. Extract and clean text from PDF\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# 2. Chunking with overlap\n",
    "def chunk_text(text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = min(start + chunk_size, len(words))\n",
    "        chunks.append(\" \".join(words[start:end]))\n",
    "        start = end - overlap  # overlap to avoid cutting useful info\n",
    "    return chunks\n",
    "\n",
    "# 3. Classify which sections a chunk contains\n",
    "def classify_chunk(chunk: str) -> List[str]:\n",
    "    prompt = f\"\"\"\n",
    "This is a chunk of a CV:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\n",
    "Which of the following sections does it contain?\n",
    "Choose from this list only: [\"profile\", \"contact\", \"experience\", \"education\", \"projects\", \"skills\", \"none\"]\n",
    "\n",
    "Return a JSON list, like: [\"experience\", \"projects\"]\n",
    "\"\"\"\n",
    "    output = pipe(prompt)[0]['generated_text']\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        return json.loads(output.strip())\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# 4. Generate extraction prompt per section\n",
    "def get_extraction_prompt(section: str, chunk: str) -> str:\n",
    "    if section == \"experience\":\n",
    "        return f\"\"\"\n",
    "Extract experiences from this CV chunk. For each, return:\n",
    "- company_name: first word, last word\n",
    "- position_title: first word, last word\n",
    "- start_date: first word, last word\n",
    "- end_date: first word, last word\n",
    "- description: first word, last word\n",
    "Only extract from visible text (no guessing or summarizing). Return JSON only.\n",
    "CV chunk:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    elif section == \"profile\" or section == \"contact\":\n",
    "        return f\"\"\"\n",
    "Extract profile and contact info from this CV chunk. Return:\n",
    "- name: first word, last word\n",
    "- email: first word, last word\n",
    "- phone: first word, last word\n",
    "- address (if any): first word, last word\n",
    "- profile_description: first word, last word\n",
    "Return JSON only.\n",
    "CV chunk:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    elif section == \"education\":\n",
    "        return f\"\"\"\n",
    "Extract education items from this CV chunk. For each, return:\n",
    "- start word\n",
    "- end word\n",
    "Only return what exists in text. JSON only.\n",
    "CV chunk:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    elif section == \"projects\":\n",
    "        return f\"\"\"\n",
    "Extract projects from this CV chunk. For each, return:\n",
    "- title: first word, last word\n",
    "- description: first word, last word\n",
    "Only extract based on exact visible text. Return JSON only.\n",
    "CV chunk:\n",
    "\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 5. Merge extracted results\n",
    "def merge_results(aggregate: Dict, new_data: Dict) -> Dict:\n",
    "    for key, value in new_data.items():\n",
    "        if isinstance(value, list):\n",
    "            aggregate.setdefault(key, []).extend(value)\n",
    "        elif isinstance(value, dict):\n",
    "            aggregate[key] = value  # overwrite or update\n",
    "    return aggregate\n",
    "\n",
    "# 6. Process the full CV\n",
    "def process_cv(pdf_path: str):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    chunks = chunk_text(text)\n",
    "    final_result = {}\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"\\n--- Processing chunk {i+1}/{len(chunks)} ---\")\n",
    "        section_list = classify_chunk(chunk)\n",
    "\n",
    "        for section in section_list:\n",
    "            prompt = get_extraction_prompt(section, chunk)\n",
    "            if prompt:\n",
    "                output = pipe(prompt)[0]['generated_text']\n",
    "                try:\n",
    "                    parsed = json.loads(output.strip())\n",
    "                    if not isinstance(parsed, dict):\n",
    "                        parsed = {section: parsed}  # wrap if it's just a list\n",
    "                    final_result = merge_results(final_result, parsed)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Failed to parse JSON for section '{section}' in chunk {i+1}: {e}\")\n",
    "                    print(\"Raw output:\", output)\n",
    "\n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b5f2e-500e-43fb-97a3-36f64b7dc415",
   "metadata": {
    "execution": {
     "execution_failed": "2025-07-22T23:37:40.261Z",
     "iopub.execute_input": "2025-07-22T23:30:47.692041Z",
     "iopub.status.busy": "2025-07-22T23:30:47.691658Z"
    }
   },
   "outputs": [],
   "source": [
    "result = process_cv(\"CV_Achraf_HT_Directeur et Chef de projet IT_2025.pdf\")\n",
    "import pprint; pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c073f985-0124-461a-b842-964e7832ec48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
